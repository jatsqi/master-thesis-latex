\chapter{Implementation}
\label{chap:impl}
% 0.5 Seiten

	Building upon the algorithmic descriptions of Chapter \ref{chap:tree}, we want to discuss how such an algorithm can be efficiently implemented and practice and how the component is integrated into \ac{GCG} as a detector.
	The Chapter is divided into multiple sections, each describing a different aspect of the implementation:

	\begin{enumerate}
		\item Section \ref{chap:impl:architecture} contains a high-level overview about the architecture of the detector and its relation with other components in \ac{GCG}.
		\item In Sections \ref{chap:impl:architecture} - \ref{chap:impl:hashing}, we will give a brief overview about a few custom data structures required to implement the refinement more efficiently and how the tree is represented in memory.
		\item Sections \ref{chap:impl:cutoff} and \ref{chap:impl:multi} conclude the Chapter with two practical considerations:
		\begin{itemize}
			\item Is it possible to reduce to the number of candidate partitions before scoring?
			\item For larger and more complicated models, can we ensure a reasonable runtime?
		\end{itemize}
	\end{enumerate}

	This Chapter does not include actual numbers concerning space and runtime, we only look at the underlying concepts which are widely used in other algorithms to achieve e.g. a better practical runtime.

	\clearpage

	\section{Architecture}
	\label{chap:impl:architecture}
	% 2 Seiten

		\begin{figure}[ht!]
			\centering
			\includesvg[scale=0.7, inkscapelatex=false]{Bilder/PlantUML/out/comp/comp}
			\caption{text}
			\label{fig:impl:arch:overview}
		\end{figure}

		As mentioned in the introduction to Chapter \ref{chap:tree}, the approach is implemented as a \textit{Detector} in \ac{GCG}, contrary to the fact that the algorithm outputs a one or multiple partitions of constraints or variables.
		Generating such partitions is more aligned with the concept of a \textit{classifier} from Section \ref{chap:gcg:classifiers}, but this comes with an important drawback.
		Because we want to incorporate information about variables for partitioning constraints and vice-versa for constraints, we have to delay the execution of the algorithm to a point in time \textit{after} the classification has finished, i.e., all relevant data is available.
		Circumventing this problem by potentially implementing the algorithm as a classifier and assigning the lowest priority possible to it is not an option as well, because this would introduce additional maintenance overhead in case changes to the overall classification/detection framework are made.
		An implementation as a detector \textit{ensures} that all classification step are done beforehand.

		An overview about the relationship between the \ac{GCG} and the detector is shown in Figure \ref{fig:impl:arch:overview}.
		When implementing an detector, \ac{GCG} provided a set of callbacks that have to implemented such as
		\begin{itemize}
			\item Set-up/Tear-down, i.e., for allocation and deallocation of data-structures
			\item A handler for propagation, which takes a partial decomposition and assigns all or a subset of the remaining open constraints to either a block or the master. This concept was already shown in Figure \ref{fig:gcg:partialdettree}.
		\end{itemize}

		\clearpage

		The callbacks take \ac{GCG}-internal data structures as input and must provide the result as such.
		In order to ensure better maintainability, the logic realizing the tree refinement should be mostly \textit{independent} of the concrete framework it is being used in.
		Furthermore, relying on custom data structures increases control about runtime and space considerations. \todo{Wording}
		This decoupling is being realized by an \textit{Adapter}, as shown in Figure \ref{fig:impl:arch:overview}, which translates between the two \enquote{worlds} of data-structures and ensures compatibility.

	\section{Metadata}
	\label{chap:impl:meta}
	% 1 Seite

	\section{Data Structures}
	\label{chap:impl:structures}
	% 2 Seiten

		The implementation of the central tree refinement algorithm uses the following components:

		\begin{itemize}
			\item \textit{Strategies}: As explained in Section \ref{chap:tree:strategies}, strategies are responsible for refining cells. Each strategy is implemented as a separate data-structure which share a common interface.
			\item \textit{Rules}: A rule is responsible for deciding whether a certain strategy \textit{is allowed} to expand a node. Rules can be used to implement local cutoff-conditions such as \textit{Depth} or limit the set of applicable strategies dynamically.
			\item \textit{Scores}: As the name implies, scores are responsible for assigning each found candidate partition a numeric value.
		\end{itemize}

		The modular structure of the algorithm proved very flexible in terms of testing different approaches.

		\clearpage

	\section{Duplication Prevention}
	\label{chap:impl:hashing}
	% 1 Seite

		In order to keep the memory consumption of the \ac{SRT}, which represents the explored search space, as low as possible within practical bounds, we propose two ways of to achieve this goal:

		\begin{enumerate}
			\item A simple approach to storing the actual partitions and its cells in memory by leveraging knowledge about previously generated cells.
			\item We prevent the generation of \textit{identical sub-trees} by the algorithm to explore the same search space without additional computational effort.
		\end{enumerate}

		We propose two data structure for storing and indexing of individual cells and tree nodes as shown in Figure \ref{fig:impl:hashing:datastruct}.
		Both data structures require the following basic operations:

		\begin{itemize}
			\item Basic \ac{CRUD} operations including adding, deleting and containment checks via. \lstinline[mathescape]|add($\cdot$)|, \lstinline[mathescape]|remove($\cdot$)| and \lstinline[mathescape]|contains($\cdot$)| respectively.
			\item An operation to get, based on some cell or tree node object, the exact duplicate stored inside the data structure. As shown in Figure \ref{fig:impl:hashing:datastruct}, both data structures realize this via. \lstinline[mathescape]|getRepresentative($\cdot$)|
			\item A function \lstinline[mathescape]|addIfMissing($\cdot$)| adding the tree node iff it doesn't exist already. These two actions are performed \textit{atomically}.
		\end{itemize}

		While precise implementation of the hash table is not of interest here, we assume that processing common queries should be done reasonably efficient.

		\begin{figure}[ht!]
			\centering
			\includesvg[inkscapelatex=false, scale=0.8]{Bilder/PlantUML/out/setindextable/setindextable}
			\caption{text}
			\label{fig:impl:hashing:datastruct}
		\end{figure}

		In the following, we will propose two ways of implementing appropriate hashing functions to realize such data structures.
		With these, we can reduce memory consumption \textit{and} implement the sub-tree duplication mechanism mentioned in Section \ref{chap:impl:cutoff} efficiently.

		\clearpage

		\subsubsection{Hashing for single cells}

		In order to keep the \textit{size} of the \ac{SRT} in terms of its actual footprint in RAM as small as possible, we propose a simple solution based on hashing.
		As soon as a strategy refines a set $S$, we get a partition $\pi = \{ A_1, A_2, \ldots, A_k \}\in \Pi(S)$.
		The cells of all found partitions including $A_1, A_2, \ldots, A_k$ are stored in a central data structure and assigned a unique index each.
		Cells that are already stored in the data structure are \textit{not} added again to reduce memory consumption.
		The duplication check for a cell $A = \{ o_1, o_2, \ldots, o_n \}$ is done by computing $x = \Call{HashList}{A}$ and probing the data structure for $x$.
		If no match was found, we add the set to the data structure.
		If a match was found, we abort.

		\subsubsection{Hashing for \ac{SRT} Nodes}

		Based on $\textproc{HashList}$, we can define a hash function for nodes of a given \ac{SRT} $T = \srt$ in a similar manner as for individual cells:
		%
		\MakeRobust{\Call}
		\begin{equation*}
			\mathrm{HashTreeNode}(v) = \Call{HashList}{\Call{Sort}{\{ \mathrm{CellId}(C) \mid \forall C \in \mathrm{Cells}_v \} }}
		\end{equation*}
		%
		The function $\textproc{CellId}$ probes the data structure mentioned in the previous Section for the unique id of the cell.
		This way, two nodes with identical cells are also assigned the same sequence of ids.
		Note that the extracted node-ids are sorted before the hashing, because the output of $\textproc{HashList}$ is dependent on the \textit{order} of the elements in the list.
		It can be expected that any given node only consists of a small number of cells and function $\textproc{HashList}$ can be implemented very efficiently, $\textproc{HashTreeNode}$ can be as well.
		Thus, by keeping a table mapping hash values to its associated nodes in memory, we can check for duplicates without a linear search through $V$.
		In case a duplication of tree nodes is detected, we have to test for equality of the two nodes to account for hash collisions.
		Here, testing for equality of two nodes $v_1, v_2 \in V$ can be done by evaluating $\mathrm{Cells}_{v_1} = \mathrm{Cells}_{v_2}$ for this single pair.

		\clearpage

	\section{Concurrency}
	\label{chap:impl:multi}
	% 1 Seite

		\begin{figure}[ht!]
			\centering
			\includesvg[scale=0.4, inkscapelatex=false]{Bilder/Hierarchy/hierarchy_binpack_NOP.svg}
			\caption{text}
			\label{fig:impl:threading}
		\end{figure}

		In addition to the optimizations via. hashing and conditional termination of the search mentioned in Sections \ref{chap:impl:cutoff} and \ref{chap:impl:hashing}, which primarily focused on reducing memory requirements, we now propose a method to reduce the actual runtime.
		Based on the description of the overall algorithm from Chapter \ref{chap:tree}, we recall two important properties:

		\begin{enumerate}
			\item When no global cutoff conditions are being used, a node of the \ac{SRT} is expanded is always expanded in the same way regardless of its position in the tree.
			\item The set $\mathrm{Cells}_v$ for all nodes only depends on the parent cell. \todo{Wording}
		\end{enumerate}

		Therefore, we can parallelized the algorithm rather easily by using a centralized queue which is explained in more detail in Section \ref{chap:impl:threading:queue}.
		In general, a queue is a data-structure providing access to a set of mutable elements in first-in first-out order.
		For the purposes of this Section, we require the existence of three methods for accessing the elements:

		\begin{enumerate}
			\item \lstinline[mathescape]|push($\cdot$)|, adding an element to the end of the queue.
			\item \lstinline[mathescape]|pop($\cdot$)|, returning the last element of the queue and removing it.
			\item \lstinline|size()|, returning the amount elements still remaining in the queue.
		\end{enumerate}

		The queue $Q = \{ q_1, q_2, \ldots, q_n \}, q_i \in V$ for a \ac{SRT} $T = \srt$ is initialized with $R$. Afterwards, a fixed amount of \textit{workers} is started that will perform the following steps until an \textit{termination signal} is received or no further progress can be made.
		A high-level overview of the logic executed by a single worker is shown in Algorithm \ref{algo:impl:queue}.
		An exact implementation for the termination signal is omitted, but a proposal can be found in Section \ref{chap:impl:threading:queue}.
		Because of the multi-threaded nature of this approach, the queue and all auxiliary data-structures used \textit{must} provide appropriate synchronization to prevent race-conditions.

		\begin{algorithm}[ht!]
			\centering
			\begin{algorithmic}
				\Require An instance $treeNodeTable$ of the Tree Node Table from Figure \ref{fig:impl:hashing:datastruct}, a $queue$ shared among all workers, a list of $strategies$.
				\Ensure None
				\Statex
				%
				\Function{Worker}{treeNodeTable, queue, strategies}
					\While{true}
						\If{termination signal received}
							\State \Return \Comment{Shutdown worker}
						\EndIf
						\State $q \gets \Call{Pop}{queue}$
						\For{$cell \gets \mathrm{Cells}_q$}
							\For{$f_{\mathrm{strat}} \in strategies$}
								\State $refined \gets f_{\mathrm{strat}}(cell)$
								\If{$refined$ violates a cutoff-condition}
									\State \textbf{continue}
								\EndIf
								\State $treeNode \gets$ create new tree node for $refined$
								\State $added \gets $ \Call{addIfMissing}{treeNodeTable, treeNode}
								\If{$added$ is true} \Comment{Only add to queue if no duplicate}
									\State \Call{Push}{queue, treeNode}
								\EndIf
							\EndFor
						\EndFor
					\EndWhile
				\EndFunction
			\end{algorithmic}
			\caption{Algo}
			\label{algo:impl:queue}
		\end{algorithm}

		\clearpage

		\section{Queue}
		\label{chap:impl:threading:queue}

