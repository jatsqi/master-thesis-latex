\chapter{\acf{GCG}}
\label{chap:gcg}
% 1 Seite

	\begin{figure}[ht!]
		\centering
		\includesvg[scale=0.8]{Bilder/DrawIO/detection_overview}
		\caption{A simplified overview of the four major stages of solving a model with \acs{GCG}.}
		\label{fig:gcg:overview}
	\end{figure}

	In this chapter, we introduce \acf{GCG}, a decomposition solver which is based on the open-source MIP-Solver \ac{SCIP} \cite{gamrathExperimentsGenericDantzigWolfe2010}.
	Readers already experienced with GCG and its capabilities may still find some details and observations interesting.
	For a given problem, \acs{GCG} is able to perform an automatic Dantzig-Wolfe reformulation which is then solved using a branch-price-and-cut algorithm.
	Alternatively, \ac{GCG} support a special \textit{Benders-Mode} which reformulated the problem using Benders decomposition.
	
	In contrast to other open-source solvers like \acfreverse{BaPCod} \cite{sadykovBaPCodGenericBranchandprice2021} or commercial software such as \textit{SAS} \cite{SASDataAI} which rely solely on user-provided decompositions, \ac{GCG} is able to automatically detect different kinds of structures algorithmically, including but not limited to
	\begin{itemize}
		\item Single-Bordered structures
		\item Arrowhead structures using the third-party tool \acfreverse{hMETIS} \cite{karypisMultilevelHypergraphPartitioning1997}.
		\item Staircase structures
	\end{itemize}
	\todo{Entfernen und auf Kapitel vorher ref}
	
	The solving process in divided into multiple consecutive stages as shown in Figure \ref{fig:gcg:overview}. Each stage will be explained in more detail in the following section as needed.
	The detection in particular aims to make \ac{GCG} more accessible to a wider range of users which do not necessarily have the required theoretical background and practical experience to reformulate linear programs on their own.
	For more details about individual features and capabilities, we refer to the official documentation \cite{GCG}. \todo{Kurz die 4 Schritte aus Bild erw√§hnen und einen Satz}

	\section{Detection}
	% 2 Seiten, Detection Loop etc.
	
		\begin{figure}[ht!]
			\centering
			\includesvg[scale=0.7]{Bilder/DrawIO/detection_loop}
			\caption{A simplified overview of the detection process and its detection loop.}
			\label{fig:gcg:detectionloop}
		\end{figure}
	
		As mentioned in the introduction to this chapter, one integral part and distinguishing feature of \ac{GCG} is its detection framework.
		A simplified overview of the detection currently \footnote{\ac{GCG} version 3.5, as of 2025-07-18.} implemented in \ac{GCG} is shown in Figure \ref{fig:gcg:detectionloop}. For a more detailed visualization including additional information about how pre-solving is handled we refer to the official documentation \cite{GCG}.
		The framework consists of two major parts:
		
		\begin{enumerate}
			\item A \textbf{classification} step, in which a set of classifiers is partitioning the constraints (and variables) according to a certain property, producing one partition each.
			The goal of this step is to detect different underlying structures of the constraint matrix, which can be used during the detection loop to make more informed decisions about which constraints to assign to which block or master.
			Important classifiers for the remainder of this thesis are discussed in more detail in Section \ref{chap:gcg:classifiers}.
			\item The \textbf{detection loop}, which consists of a set of detectors which are responsible for assigning constraints either the master or to individual blocks.
			In round $n+1$ a detector receives a \textit{partial} decomposition, that is, a decomposition in which \textit{not all} constraints are assigned yet, from round $n$ as input and pushes a set of newly created (partial) decompositions to a queue.
			In case the user did not provide a partial decomposition as input in round $0$, the loop is initialized with a decomposition in which no constraint is assigned yet.
		\end{enumerate}
	
		\begin{figure}[ht!]
			\centering
			\includegraphics{Bilder/DrawIO/partialdec_tree_pdf}
			\caption{Visualization of the induced tree of propagated partial decompositions.}
			\label{fig:gcg:partialdettree}
		\end{figure}
		
		The concept of detecting structures in different rounds is visualized in Figure \ref{fig:gcg:partialdettree}.
		Starting from a root decomposition in which all constraints are still unassigned or \enquote{open}, different detectors produce a set of new partial decomposition.
		Depending on the configuration, a detector is not allowed to work on a certain partial decomposition or its decedents twice.
		A very simple but concrete example of how such a tree might look like in practice can be found in Section \ref{chap:gcg:example}.
		
		Furthermore, if no detector found any new decomposition in round $k$, or $k$ exceed the maximum number of rounds, the detection loop is stopped and all complete decomposition are collected, scored and exactly one is chosen for which the solving is started. \todo{Grammatik, Wortwahl}
		The scoring and selection stage is of particular interest in practice, because the tree in Figure \ref{fig:gcg:partialdettree} might grow beyond thousand of decompositions, of which the best in terms of solving time or a different metric must be selected.
		Because the scoring of decompositions is not of major interest for \textit{this} thesis, we refer to the official documentation for details \cite{GCG}.
	
	\clearpage
	
	\section{Classifiers}
	\label{chap:gcg:classifiers}
		% 1 Seite, Var Classifiers
		% 1 Seite, Cons Classifiers

		As mentioned in the introduction to this chapter, classifiers are responsible for detecting different underlying structures of the constraint matrix, which can be used during the detection loop to make more informed decisions about which constraints to assign to which block or master.
		Given a set of constraints $C = \{ c_1, c_2, \ldots, c_m \}$, classifiers can be seen as a \textit{injective} function $f: C \mapsto \mathbb{Z}$, i.e., a function that assigns each constraint to exactly one number or \textit{class}.
		Note that in \acs{GCG}, classifiers are allowed to only classify a subset $C' \subseteq C$, leaving $C \setminus C'$ unassigned to any class \footnote{When using \ac{GCG} as a library, this can be checked via. \lstinline|IndexPartition::isIndexClassified|.}.
		In the current version of \ac{GCG}, however, all classifiers always assign every constraint to some class.
		
		\subsection{Name Classifiers}
		
			The names of constraints and variables are, if provided, a strong indicator to which constraints or variables are related to each other.
			The names usually consist of two parts:
			\begin{enumerate}
				\item The semantic group name, such as \enquote{capacity} or \enquote{link} for e.g. a Bin-Packing model. 
				\item A \textit{modifier}, which usually consists of numbers, capital letters or a combination of both. Typically, the modifier is separated from the semantic group name via.  non alpha-numeric characters such as \enquote{\_} or \enquote{\#}.
			\end{enumerate}
		
			Constraints in the same group typically share similar names, with the \textit{modifier} being the only differentiating factor. For example, in a Bin-Packing problem, capacity constraints such as \enquote{capacity\_1}, \enquote{capacity\_2}, $\ldots$ usually vary only in the index indicating the bin. This similarity can be quantified using metrics like the \textit{Levenshtein Distance}, which is the minimum number of single-character edits required to change one word into the other.
			
			Given a alphabet $\Sigma$, words $w, v \in \Sigma^*$ over that alphabet, then the \textit{Levenshtein} distance between those two words can be computed as:
			%
			\begin{equation}
				\label{eq:gcg:levenshtein}
				\mathrm{lev}(w, v) = \begin{cases}
					|w| & \mathrm{if} \; v = \epsilon \\
					|v| & \mathrm{if} \; w = \epsilon \\
					\mathrm{lev}(\mathrm{prefix}(w), \mathrm{prefix}(v)) & \mathrm{if} \; \mathrm{head}(w) = \mathrm{head}(v) \\
					1 + \min \begin{cases}
						\mathrm{lev}(\mathrm{prefix}(w), v) \\
						\mathrm{lev}(w, \mathrm{prefix}(v)) \\
						\mathrm{lev}(\mathrm{prefix}(w), \mathrm{prefix}(v)) \\
					\end{cases} & \mathrm{otherwise}
				\end{cases}
			\end{equation}
			%
			Equation \ref{eq:gcg:levenshtein} can be computed in $O(|w| \cdot |v|)$ using a dynamic programming approach.
			Let $B = (\mathrm{lev}(\mathrm{name}(c_i), \mathrm{name}(c_j)))_{1 \leq i,j \leq m}$ the pair-wise Levenshtein Distance between constraint names, $k \in \mathbb{N}$ the \textit{connectivity} and $G = (V, E)$ with $V = \{ c_1, c_2, \ldots, c_m \}, E = \{ \{ u, v \} \mid u, v \in V, u \neq v, \mathrm{lev}(\mathrm{name}(u), \mathrm{name}(v)) \leq k \}$.
			Furthermore, let $reach(v) = \{ u \in V \mid (v, u) \in E \}$ be the set of reachable vertices from vertex $v \in V$.
			Then two constraints $c_i, c_j \in V$ are in the same class iff $c_j \in reach(c_i)$.
			A small example of this concept is shown in Figure \ref{fig:gcg:levenshtein}.
			\todo{5000 cons limit}
			
			\begin{figure}[ht!]
				\centering
				\includesvg[scale=0.8]{Bilder/DrawIO/levenshtein}
				\caption{The graph of pair-wise Levenshtein weights for three capacity constraints. For $k=1$, the edge between $capacity_3$ and $capacity_{12}$ vanishes, but because they is still a connecting path via. $capacity_1$, both constraints are assigned to the same class.}
				\label{fig:gcg:levenshtein}
			\end{figure}
		
		\subsection{Numeric Classifiers}
			
			\subsubsection{Nonzero}
			
				\begin{figure}[ht!]
					\centering
					\begin{equation*}
						A \; = \; \begin{pNiceMatrix}[first-row,first-col,last-col]
							& x_1 & x_2 & x_3 & x_4 & \; \textcolor{red}{class} \\
							{cons}_1 \; & 1 & 5 & -1 & -1 & \quad \textcolor{red}{4} \\
							{cons}_2 \; & 20 & 0 & 0 & 20 & \quad \textcolor{red}{2} \\
							{cons}_3 \;& 20 & 10 & 10 & 0 & \quad \textcolor{red}{3} \\
							{cons}_4 \; & 0 & 100 & -100 & 100 & \quad \textcolor{red}{3} \\
						\end{pNiceMatrix}
					\end{equation*}
					\caption{A constraint matrix with coefficients for each variable. Each constraint is assigned to a class corresponding to its number of non-zero entries.}
					\label{fig:gcg:nonzero}
				\end{figure}
				
				The nonzero classifier classified constraints according to their number of non-zero variable coefficients as shown in Figure \ref{fig:gcg:nonzero}.
				Many types of models including Bin-Packing and Cutting-Stock consist only of constraint groups with a rather \enquote{stable} internal structure, i.e., the capacity constraint for each bin in model \ref{eq:gcg:example:capacity} \todo{Wrong ref} consist of the same number of variables, because each constraint is just a sum over all items differing only in index for the respective bin.
				In general, constraint groups that are suited for this type of classifiers usually involve summations over fixed-sized sets (e.g. a set of items or bins) whose choice is not dependent on any quantified variable.
				Example for the latter include problems whose formulation is based on graphs and usually contains flow-conservation constraints shown in Equation \ref{eq:gcg:numerics:flow}. 
				%
				\begin{equation}
					\label{eq:gcg:numerics:flow}
					\sum_{u \in E(v)} x_{uv} - \sum_{u \in E^{-1}(v)} x_{vu} = 0\quad \forall v \in V
				\end{equation}
				%
				The amount of non-zeros in these constraint is entirely dependent on the number of outgoing and incoming edges for each vertex.
		
			\subsubsection{Objective}

				
			
				\clearpage
		
		\subsection{Type Classifiers}
		\label{chap:gcg:classifiers:type}
		
			Classifiers based 
			
			\subsubsection{SCIP Types}
			
				When using \ac{GCG} as a library, the type of a variable or constraint can be retrieved via. \lstinline|SCIPconsGetType(cons)| or \lstinline|SCIPvarGetType(cons)| respectively.
				The former function is not provided by \ac{SCIP} itself, but is implemented in \ac{GCG} instead.
				The implementation compares the name of the handler the constraint is assigned to and compares it to a known list of constraint handlers. \todo{the}
				The list of supported handlers includes \emph{Knapsack}, \emph{Set Partitioning}, \emph{Set Covering}, \emph{Set Packing}, \emph{Varbound} and \emph{General}, in case no special structure was detected. \todo{Check List}
				Variables can be classified as \emph{Integer}, \emph{Binary} or \emph{Continuous}
				\footnote{There are more types of variables in newer versions of \ac{SCIP} such as \emph{Implicit Integer}, but these three basic types are sufficient for the purpose of this discussion.}.
				
				The clear downside of this classification is its important precondition.
				In order to use this feature properly and retrieve a meaningful type via. the two methods, pre-solving must have been executed prior to detection.
				When \ac{GCG} reads the problem as e.g. an \lstinline|.lp| file, all constraints are added as linear constraints to the underlying \ac{SCIP} model.
				These constraints are usually \enquote{upgraded} if possible, that is, their structure is analyzed and assigned to the correct constraint handler during pre-solving.
				This is done to take advantage of properties only possessed by certain types of constraints, e.g. a solution to a set of Knapsack constraints \textit{can} be computed more efficiently by using an algorithm based on dynamic programming.
				For more detailed information we refer to the official documentation \cite{SCIPDoxygenDocumentation}.
				
				Preliminary testing showed that it is not trivial to configure the pre-processing in such a way that \textit{only} the upgrade mechanism is triggered and variables and constraints remain unchanged. \todo{Add test config to appendix}
				
				\clearpage
		
			\subsubsection{MIPLIB Constraint Types}
			
				\begin{table}[ht!]
					\centering
					\begin{tabular}{l|l|l|l}
						\textbf{Nr.} & \textbf{Type} & \textbf{Linear Constraint} & \textbf{Notes} \\
						\hline
						\hline
						1 & Empty & $\emptyset$ & - \\
						2 & Free & $-\infty \leq x \leq \infty$ & No finite side. \\
						3 & Singleton & $a \leq x \leq b$ & - \\
						4 & Aggregation & $ax + by = c$ & - \\
						5 & Precedence & $ax - ay \leq b$ & $x$, $y$ have same type. \\
						6 & Variable Bound & $ax + by \leq c$ & $x \in \{0, 1\}$ \\
						7 & Set Partitioning & $\sum 1 x_i = 1$ & $\forall i: x_i \in \{0, 1\}$ \\
						8 & Set Packing & $\sum 1 x_i \leq 1$ & $\forall i: x_i \in \{0, 1\}$ \\
						9 & Set Covering & $\sum 1 x_i \geq 1$ & $\forall i: x_i \in \{0, 1\}$ \\
						10 & Cardinality & $\sum 1 x_i = b$ & $\forall i: x_i \in \{0, 1\}, b \in \mathbb{N}_{\geq 2}$ \\
						11 & Invariant Knapsack & $\sum 1 x_i \leq b$ & $\forall i: x_i \in \{0, 1\}, b \in \mathbb{N}_{\geq 2}$ \\
						12 & Equation Knapsack & $\sum a_i x_i = 1$ & $\forall i: x_i \in \{0, 1\}, b \in \mathbb{N}_{\geq 2}$ \\
						13 & Bin Packing & $\sum a_i x_i + ay \leq a$ & $\forall i: x_i, y \in \{0, 1\}, b \in \mathbb{N}_{\geq 2}$ \\
						14 & Knapsack & $\sum a_i x_i \leq b$ & $\forall i: x_i \in \{0, 1\}, b \in \mathbb{N}_{\geq 2}$ \\
						15 & Integer Knapsack & $\sum a_i x_i \leq b$ & $\forall i: x_i \in \mathbb{Z}, b \in \mathbb{N}$ \\
						16 & Mixed Binary & $\sum a_i x_i + \sum p_j s_j \; \{\leq, =\} \; b$ & $\forall i: x_i \in \{0, 1\}, \forall j: s_j \; \mathrm{continuous}$ \\
						17 & General Linear & $\sum a_i x_i \; \{\leq, \geq, =\} \; b$ & No special structure.
					\end{tabular}
					\caption{The structure of all 17 constraint types MIPLIB keeps track of.}
					\label{table:constypes:miplib}
				\end{table}
				
				In order to get a more fine-grained classification based on constraint types.
				Because all types shown in Table \ref{table:constypes:miplib} are deducible only from \textit{local} information such as type of variables and right hand side coefficient, the types can be detected after one pass over the constraint matrix.
		\clearpage
	
	\section{Existing Detectors}
	% 1 Seite, trivial Detectors
	% 1 Seite, HMETIS Detectors
	% 1 Seite , other Detectors
	
		\begin{table}[ht!]
			\centering
			\begin{tabular}{l|l|l}
				\textbf{Nr.} & \textbf{Master} & \textbf{Open} \\
				\toprule
				\toprule
				1 & (\ref{eq:gcg:example:link}) & (\ref{eq:gcg:example:capacity}) \\ 
				2 & (\ref{eq:gcg:example:capacity}) & (\ref{eq:gcg:example:link}) \\
				3 & (\ref{eq:gcg:example:link}), (\ref{eq:gcg:example:capacity}) & -
			\end{tabular}
			\caption{For each classifier, the \textit{cons class} detector will produce $2^k - 1$ new partial decompositions with $k$ being the number of classes.}
			\label{table:gcg:example:consclass}
		\end{table}
	
		\clearpage
		A\clearpage
		A\clearpage
	
	\section{Example}
	\label{chap:gcg:example}
	
		\begin{figure}[ht!]
			\centering
			\begin{align}
				&\min &\sum_{j=1}^m y_j \nonumber \\
				&\text{s.t.} &\sum_{j=1}^m x_{ij} &= 1 &&\forall i \in \mathcal{I} \label{eq:gcg:example:link} \\
				&& \sum_{i=1}^n a_i x_{ij} &\leq C y_j && \forall j \in \mathcal{J} \label{eq:gcg:example:capacity} \\
				&& x_{ij} &\in { 0, 1 } && \forall i \in \mathcal{I}, \forall j \in \mathcal{J} \nonumber \\
				&& y_j &\in { 0, 1 } && \forall j \in \mathcal{J} \nonumber
			\end{align}
			\caption{Bin-Packing Model with items $\mathcal{I} = \{ 1, \ldots, n \}$, item sizes $a_i \in \mathbb{Z}_{\geq 0}$, bins $\mathcal{J} = \{ 1, \ldots, m \}$ and capacity $C$.}
			\label{figure:gcg:example:binpack}
		\end{figure}
		\todo{Bild}
		
		In order to illustrate the detection with a concrete example, we revisit the textbook Bin-Packing model shown in Figure \ref{figure:gcg:example:binpack}.
		Constraints \ref{eq:gcg:example:link} enforce that every item is packed in exactly one bin, while inequalities \ref{eq:gcg:example:link} ensure that the capacity of each bin is respected if some item is packed in it.
		The objective is to minimize the number of bins.
		
		Without pre-solving enabled, a classifier such as MIPLIB would assign constraints \ref{eq:gcg:example:link} and \ref{eq:gcg:example:capacity} to the classes \textit{Set Partitioning} and \textit{Bin-Packing} respectively.
		If unique, this classification is added to a list provided to the detection stage.
		
		If no further classifications are found, the \textit{cons class} detector will yield 3 new partial decompositions, first assigning constraints \ref{eq:gcg:example:link}, then \ref{eq:gcg:example:capacity} and finally both \ref{eq:gcg:example:link} and \ref{eq:gcg:example:capacity} to the master.
		The constraint group not assigned to the master remains \textit{open}.
		
		During the next round of detection, a detector such as \textit{Connected Base} will receive the partial decomposition with only the packing constraints assigned to the master as input.
		Here, the induced constraint adjacency graph of the $q \ge 0$ open capacity constraints consists of $q$ isolated connected components, forming the desired block-diagonal structure.
		
		